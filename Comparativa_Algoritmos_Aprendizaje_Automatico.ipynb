{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3427e741-2f96-4e4c-ac3e-f7464fe461d8",
   "metadata": {},
   "source": [
    "<img src=\"https://www.unir.net/wp-content/uploads/2019/11/Unir_2021_logo.svg\" width=\"240\" height=\"240\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237703ca-f216-418c-8c22-7c95a417ec64",
   "metadata": {},
   "source": [
    "<center><h1>Trabajo de Fin de Master</header1></center>\n",
    "<center><h1>Comparativa de Algoritmos de Aprendizaje Automático Aplicados a la Predicción de Cáncer de Colon a Partir de Datos Nutricionales</header1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5671cfdd-e285-4abb-acb0-e92f13d2739a",
   "metadata": {},
   "source": [
    "**Trabajo fin de estudio presentado por:**\tChristian Suárez Heuvan<br>\n",
    "**Tipo de trabajo:**\tComparativa de Soluciones<br>\n",
    "**Director/a:**\tDeivis Eduard Ramírez Martínez<br>\n",
    "**Fecha:**\t24/04/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592db65-ef76-411f-b182-3daaaacec549",
   "metadata": {},
   "source": [
    "# 1 Instalación e Importación de Librerias Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2cf0ee-a1ce-4498-822d-e0a5c0d84a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/chr1zS/TFM_Comparativa_Algoritmos/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8211d47-a6cb-4399-b006-92e4e00b8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, roc_curve,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7b0a4-f314-467c-a4c5-c8591bb26394",
   "metadata": {},
   "source": [
    "# 2 Preparación del Conjunto de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4300f7-0764-41d4-b7cc-04f4ad368e4e",
   "metadata": {},
   "source": [
    "## 2.1 Carga y Fusión de los Dataset NHANES\n",
    "Se importan y fusionan los 3 ficheros NHANES usando merged, mediante la clave común SEQN:\n",
    "- Fichero DEMO_L.XPT: contiene información demográfica básica de los participantes.\n",
    "- Fichero DR1TOT_L.XPT: resume la ingesta total de nutrientes y componentes dietéticos que han sido reportados por los participantes.\n",
    "- Fichero MCQ_L.XPT: contine información médica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54ac8a-40cd-4508-b8ad-3b439576861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga directamente desde GitHub\n",
    "url_base = \"https://raw.githubusercontent.com/chr1zS/TFM_Comparativa_Algoritmos/main/\"\n",
    "\n",
    "# Carga de datasets NHANES\n",
    "demo = pd.read_sas(url_base + \"DEMO_L.XPT\", format='xport')\n",
    "diet = pd.read_sas(url_base + \"DR1TOT_L.XPT\", format='xport')\n",
    "mcq = pd.read_sas(url_base + \"MCQ_L.XPT\", format='xport')\n",
    "\n",
    "# Comprobación dimensiones de cada dataset\n",
    "print(\"DEMO:\", demo.shape)\n",
    "print(\"DIET:\", diet.shape)\n",
    "print(\"MCQ:\", mcq.shape)\n",
    "\n",
    "# Fusion de datasets DEMO y DIET\n",
    "merged = demo.merge(diet, on=\"SEQN\", how=\"inner\")\n",
    "\n",
    "# Fusion de resultado anterior con datasert MCQ\n",
    "merged = merged.merge(mcq, on=\"SEQN\", how=\"inner\")\n",
    "\n",
    "# Comprobación dimensiones finales\n",
    "print(\"Dataset combinado:\", merged.shape)\n",
    "\n",
    "# Revisión de 5 primeras filas de los 3 datsets juntos\n",
    "merged.head()\n",
    "\n",
    "# Guardado datset como CSV\n",
    "merged.to_csv(\"datasetsalud.csv\", index=False)\n",
    "\n",
    "print(\"Dataset guardado como datasetsalud.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf67ac7-90df-433b-8d03-490d90debda5",
   "metadata": {},
   "source": [
    "## 2.2 Limpieza del Conjunto de Datos\n",
    "Limpieza y preparación del conjunto de datos para su utilización en por los algoritmos de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3736b0-bd33-4258-a1ca-60533b450df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "df = pd.read_csv(\"datasetsalud.csv\")\n",
    "\n",
    "# Selección de las columnas relevantes para el estudio\n",
    "columnas_interes = {\n",
    "    'RIDAGEYR': 'Edad',\n",
    "    'RIAGENDR': 'Genero',\n",
    "    'DR1TCARB': 'Carbohidratos',\n",
    "    'DR1TSUGR': 'Azucares',\n",
    "    'DR1TALCO': 'Alcohol',\n",
    "    'MCQ220': 'Cancer',\n",
    "    'MCQ230A': 'Cancer_Colon1',\n",
    "    'MCQ230B': 'Cancer_Colon2',\n",
    "    'MCQ230C': 'Cancer_Colon3'\n",
    "    \n",
    "}\n",
    "df = df[list(columnas_interes.keys())].rename(columns=columnas_interes)\n",
    "\n",
    "# Comprobación selección de columnas necesarias\n",
    "print(\"Dataset renombrado: \")\n",
    "print(df.head(6))\n",
    "\n",
    "# Normalización las columnas \"Cáncer de Colon\": 16 significa tener Cáncer de Colon. \n",
    "# Si se encuentra un 16 lo cambiamos a 1 ya que 1 significa tener Cáncer de Colon. Cualquier cosa diferente a 16 se pondrá un 2.\n",
    "df['Cancer_Colon1'] = df['Cancer_Colon1'].apply(lambda x: 1 if x == 16 else 2)\n",
    "df['Cancer_Colon2'] = df['Cancer_Colon2'].apply(lambda x: 1 if x == 16 else 2)\n",
    "df['Cancer_Colon3'] = df['Cancer_Colon3'].apply(lambda x: 1 if x == 16 else 2)\n",
    "\n",
    "# Fusión las 3 columnas Cáncer de Colon en una sola\n",
    "df['Cancer_Colon'] = df[['Cancer_Colon1', 'Cancer_Colon2', 'Cancer_Colon3']].apply(\n",
    "    lambda row: 1 if 1 in row.values else 2, axis=1\n",
    ")\n",
    "\n",
    "# Eliminación las 3 columnas\n",
    "df.drop(['Cancer_Colon1', 'Cancer_Colon2', 'Cancer_Colon3'], axis=1, inplace=True)\n",
    "print (df['Cancer_Colon'].value_counts().get(1, 0))\n",
    "\n",
    "# Reemplazo de todos los NaN por 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Reemplazo de valores muy pequeños por 0\n",
    "for col in df.select_dtypes(include='number').columns:\n",
    "    df[col] = df[col].apply(lambda x: 0 if isinstance(x, float) and x < 1e-10 else x)\n",
    "\n",
    "# Verificación de valores extremos\n",
    "valores_extremos = df[['Carbohidratos', 'Azucares', 'Alcohol']].describe()\n",
    "print(valores_extremos)\n",
    "\n",
    "# Guardado del dataset limpio\n",
    "df.to_csv(\"datasetsalud_limpio.csv\", index=False)\n",
    "print(\"Dataset preprocesado: \", df.shape)\n",
    "\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b1b72-191a-46c8-a9e9-38f6b95e23e5",
   "metadata": {},
   "source": [
    "# 3 Evaluación con Modelos Predictivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78114aad-a4e1-4013-8829-6824e968de51",
   "metadata": {},
   "source": [
    "## 3.1 Carga y División del Conjunto de Datos\n",
    "Carga del conjunto de datos previamente preparado, se establecen las variables de entrada del modelo y de salida. Por ultimo se divide el conjunto de datos en entrenamiento y prueba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fde661-503e-4882-b9db-f9a32e1eaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga del conjunto de datos\n",
    "df = pd.read_csv(\"datasetsalud_limpio.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Filtra para seleccionar solo personas con algún tipo de cáncer\n",
    "df_cancer = df[df[\"Cancer\"] == 1]\n",
    "\n",
    "# Dado que 1 es no tener cancer y \n",
    "#y = y.map({1: 0, 2: 1})  # 1 → No tiene, 2 → Sí tiene (reconvertido a 0/1)\n",
    "\n",
    "# Definición del conjunto de variables predictorias (x) y variable objetivo (y)\n",
    "X = df_cancer[[\"Carbohidratos\", \"Azucares\", \"Alcohol\"]]\n",
    "y = df_cancer[\"Cancer_Colon\"]\n",
    "print(\"Distribución original de clases:\\n\", y.value_counts())\n",
    "\n",
    "# División del conjunto de datos\n",
    "# Diviión de datos en entrenamiento y prueba (80%-20%) manteniendo la proporción de clases mediante muestreo estratificado.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd11876-e4e2-4fed-8107-a91540aacbcd",
   "metadata": {},
   "source": [
    "## 3.2 Escalado y Balanceo\n",
    "Dado que la clase positiva Cancer_Colon = 1 representaba un porcentaje muy pequeño del total, se produjo un desequilibrio lo cual afecta negativamente el rendimiento de los modelos de clasificación, obteniendo un 0 como valor para muchos estadísticos. Para solucionar este inconveniente de aplicaron dos estrategias:\n",
    "- SMOTE para aumentar artificialmente los ejemplos de la clase minoritaria. Se usa en todos los modelos\n",
    "- class_weight=’balanced’ para que los errores en la clase minoritaria, afirmativo en cáncer de colon, tenga mayor peso en el entrenamiento. Se usa en todos los modelos excepto en la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3c8be-9836-4943-ac2d-a6852600bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se estandarizan los datos de prueba, transformándolos para que tengan media 0 y desviación estándar 1\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "#Generación de muestras sintéticas para balancear las clases del conjunto de entrenamiento y luego estandariza los datos resultantes.\n",
    "smote = SMOTE(random_state=42)\n",
    "# Modelo sin escalar\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "# Modelo con StandarScaler\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db9135-7b04-4424-bbf7-868f54ccc1d3",
   "metadata": {},
   "source": [
    "## 3.3 Definición de Modelos\n",
    "Definiciaón de los 4 modelos que se compararán para la predicción de cáncer:\n",
    "- Árbol de Decisión\n",
    "- Random Forest\n",
    "- Regresión Logística\n",
    "- Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc5746-b8a8-4c0d-b709-6d108001a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de un diccionario con cuatro modelos de clasificación supervisada.\n",
    "# El desbalance de clases de los 3 primero modelos se trata mediante el parámetro class_weight='balanced'\n",
    "modelos = {\n",
    "    \"Árbol de Decisión\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"Regresión Logística\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    # MLPClassifier no admite el parámetro class_weight. El desbalance se compensa previamente aplicando SMOTE sobre los datos de entrenamiento.\n",
    "    \"Red Neuronal\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7158afb1-13cc-4a61-8cf1-93ed65f3285e",
   "metadata": {},
   "source": [
    "## 3.4 Entrenamiento y Evaluación de Modelos\n",
    "Entrenamiento con cada uno de los cuatro modelos escogidos. Para el Árbol de Decisión y Random Forest se utilizaron los datos balanceados sin estandarizar, ya que estos modelos no requieren normalización. En cambio, para la Regresión Logística y la Red Neuronal se utilizaron los datos balanceados y estandarizados, dado que estos modelos son sensibles a la escala de los datos.<br>\n",
    "Para cada modelo se calcularon las siguientes métricas: Accuracy o exactitud, Precisión, Recall que indica la sensibilidad o tasa de verdaderos positivos, F1-Score que indica la media armónica entre precisión y recall y el AUC-ROC o área bajo la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413667f2-46cd-4457-a29f-0138050d2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos lista vacia\n",
    "resultados = []\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\nEvaluación del modelo: {nombre}\")\n",
    "    start_time = time.time()  # Inicia el cronómetro para medir tiempos de entrenamiento\n",
    "\n",
    "    # Uso de datos escalados (datos con la misma escala: media=0 desviación standar=1) solo para la Regresión Logística y la Red Neuronal\n",
    "    # y datos sin escalar para los demás ya que no todos los algoritmos requieren normalización\n",
    "    if nombre in [\"Regresión Logística\", \"Red Neuronal\"]:\n",
    "        modelo.fit(X_train_resampled_scaled, y_train_resampled)\n",
    "        y_pred = modelo.predict(X_test_scaled)\n",
    "        y_proba = modelo.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        modelo.fit(X_train_resampled, y_train_resampled)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    end_time = time.time()  # Termina el cronómetro de tiempo de entrenamiento\n",
    "    training_time = end_time - start_time  # Duración en segundos\n",
    "    print(f\"Tiempo de entrenamiento: {training_time:.4f} segundos\")\n",
    "\n",
    "    # Gerenación del informe de clasificación con métricas\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    # Cálculo del valor AUC-ROC\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"AUC ROC: {round(auc, 4)}\")\n",
    "\n",
    "    # Se muestran todos os resultados\n",
    "    resultados.append({\n",
    "        \"Modelo\": nombre,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, pos_label=1, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, pos_label=1, zero_division=0),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred, pos_label=1, zero_division=0),\n",
    "        \"AUC ROC\": auc,\n",
    "        \"Tiempo Entrenamiento\": training_time\n",
    "    })\n",
    "    \n",
    " # Generación de la Curva ROC por modelo\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba, pos_label=1)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, label=f\"{nombre} (AUC = {auc:.2f})\", linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "    plt.title(f\"Curva ROC - {nombre}\", fontsize=12)\n",
    "    plt.xlabel(\"Tasa de Falsos Positivos (FPR)\")\n",
    "    plt.ylabel(\"Tasa de Verdaderos Positivos (TPR)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"curva_ROC_{nombre.replace(' ', '_').lower()}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ff537-e972-433a-9dae-ae79f1e8e36a",
   "metadata": {},
   "source": [
    "## 3.5 Comparación de Curvas ROC entre Modelos\n",
    "Generación y comparación de las curvas ROC de cada modelo, utilizando probabilidades de predicción (escaladas o no según corresponda) y calculando su AUC.\n",
    "Finalmente, se produce la generación y guardado de la gráfica con el título \"curvas_ROC_comparadas.png\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046663e4-a075-4d81-97a8-0939ae665a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Se recorre cada modelo\n",
    "for resultado, nombre in zip(resultados, modelos.keys()):\n",
    "    modelo_entrenado = modelos[nombre]\n",
    "\n",
    "    # Calculo de probabilidades de prediccón de la clase positiva (y_proba) usando datos escalados solo si el modelo es sensible a la escala,\n",
    "    # en caso contrario usa los datos originales\n",
    "    if nombre in [\"Regresión Logística\", \"Red Neuronal\"]:\n",
    "        y_proba = modelo_entrenado.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        y_proba = modelo_entrenado.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Cálculo de false positive y true positive para obtener curva ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba, pos_label=1)\n",
    "    auc = resultado[\"AUC ROC\"]\n",
    "    plt.plot(fpr, tpr, label=f\"{nombre} (AUC = {auc:.2f})\", linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1) # Trazo de la diagonal\n",
    "plt.title(\"Comparativa de Curvas ROC entre Modelos\", fontsize=13) # \n",
    "plt.xlabel(\"Tasa de Falsos Positivos (FPR)\")\n",
    "plt.ylabel(\"Tasa de Verdaderos Positivos (TPR)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6) # Grafico de cuadrícula con puntos\n",
    "plt.tight_layout() # Ajuste de márgenes de la gráfica\n",
    "plt.savefig(\"curvas_ROC_comparadas.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b85e0-08ee-49b4-8970-4ecd666be882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0da1bbbc-76f8-430f-917f-9801131aa34f",
   "metadata": {},
   "source": [
    "## 3.6 Tabla Comparativa de Resultado\n",
    "Tabla de resúmen comparativo de resultados entre los diferentes modelos ordenados por AUC ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0afa01-10ed-4c92-a3ca-0703619e9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.round(3).sort_values(by=\"AUC ROC\", ascending=False)\n",
    "\n",
    "print(\"\\nResumen comparativo de modelos (ordenado por AUC ROC):\")\n",
    "print(df_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d770d0-25b8-4c30-babc-fbded9dd54c7",
   "metadata": {},
   "source": [
    "# 4 Comparativa de los Modelos de Clasificación en Función de las Metricas Analizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f520ef3e-06c6-48a2-bb1e-2d9a5aaa658f",
   "metadata": {},
   "source": [
    "## 4.1 Comparativa de Modelos Clasificación en función de métrica F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c44d5-42de-4ad4-bfc3-5d9ea2c591d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    \"Árbol de Decisión\",\n",
    "    \"Random Forest\",\n",
    "    \"Regresión Logística\",\n",
    "    \"Red Neuronal\"\n",
    "]\n",
    "# Se añaden valores manualmente porque en cada ejecución cambian. Y estos gráficos se usaron para la explicación de la memoría.\n",
    "# es por ello, que a pesar de que pueden tomar lo valores de forma automatica, se ha decidido ponerlos manual.\n",
    "f1_scores = [0.038, 0.044, 0.056, 0.061]  #valores a sustituir\n",
    "\n",
    "# Ordenación de modelos de mayor a menor F1\n",
    "orden = sorted(zip(f1_scores, modelos), reverse=True)\n",
    "f1_scores_ordenados, modelos_ordenados = zip(*orden)\n",
    "\n",
    "# Generación del gráfico\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(modelos_ordenados, f1_scores_ordenados, color='skyblue')\n",
    "\n",
    "# Resaltado del mejor de los 4 modelos\n",
    "bars[0].set_color('mediumseagreen')\n",
    "\n",
    "# Etiquetado de valores\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval + 0.0015, f\"{yval:.3f}\",\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Mejora de la gráfica\n",
    "ax.set_title(\"Comparativa de Modelos de Clasificación (F1-score)\", fontsize=14, weight='bold')\n",
    "ax.set_ylabel(\"F1-score\")\n",
    "ax.set_ylim(0, max(f1_scores_ordenados) + 0.01)\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3477722-17eb-4113-b1bf-29cdeda613b8",
   "metadata": {},
   "source": [
    "## 4.2 Comparativa de Modelos Clasificación en función de métrica Acurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f021abe-d628-4e00-b853-fef65d653926",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    \"Árbol de Decisión\",\n",
    "    \"Random Forest\",\n",
    "    \"Regresión Logística\",\n",
    "    \"Red Neuronal\"\n",
    "]\n",
    "# Se añaden valores manualmente porque en cada ejecución cambian. Y estos gráficos se usaron para la explicación de la memoría.\n",
    "# es por ello, que a pesar de que pueden tomar lo valores de forma automatica, se ha decidido ponerlos manual.\n",
    "accuracy_scores = [0.725, 0.724, 0.253, 0.830]  # valores manuales\n",
    "\n",
    "# Ordenación de modelos de mayor a menor Accuracy\n",
    "orden = sorted(zip(accuracy_scores, modelos), reverse=True)\n",
    "accuracy_ordenados, modelos_ordenados = zip(*orden)\n",
    "\n",
    "# Generación del gráfico\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(modelos_ordenados, accuracy_ordenados, color='skyblue')\n",
    "\n",
    "# Resaltado del mejor de los 4 modelos\n",
    "bars[0].set_color('mediumseagreen')\n",
    "\n",
    "# Etiquetado\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval + 0.003, f\"{yval:.3f}\",\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Mejora de la gráfica\n",
    "ax.set_title(\"Comparativa de Modelos de Clasificación (Accuracy)\", fontsize=14, weight='bold')\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_ylim(min(accuracy_ordenados) - 0.01, max(accuracy_ordenados) + 0.01)  \n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff7313a-5682-47d0-9aed-aba63eda7142",
   "metadata": {},
   "source": [
    "## 4.2 Comparativa de Modelos Clasificación en función de métrica Presición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cfc932-b24e-4e83-bfca-6c18b64c094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    \"Árbol de Decisión\",\n",
    "    \"Random Forest\",\n",
    "    \"Regresión Logística\",\n",
    "    \"Red Neuronal\"\n",
    "]\n",
    "# Se añaden valores manualmente porque en cada ejecución cambian. Y estos gráficos se usaron para la explicación de la memoría.\n",
    "# es por ello, que a pesar de que pueden tomar lo valores de forma automatica, se ha decidido ponerlos manual.\n",
    "precision_scores = [0.023, 0.027, 0.029, 0.040]  # valores manuales\n",
    "\n",
    "# Ordenación de modelos de mayor a menor precisión\n",
    "orden = sorted(zip(precision_scores, modelos), reverse=True)\n",
    "precision_ordenados, modelos_ordenados = zip(*orden)\n",
    "\n",
    "# Generación del gráfico\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(modelos_ordenados, precision_ordenados, color='skyblue')\n",
    "\n",
    "# Resaltado del mejor de los 4 modelos\n",
    "bars[0].set_color('mediumseagreen')\n",
    "\n",
    "# Etiquetado de valores\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f\"{yval:.3f}\",\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Mejora de la gráfica\n",
    "ax.set_title(\"Comparativa de Modelos de Clasificación (Precisión)\", fontsize=14, weight='bold')\n",
    "ax.set_ylabel(\"Precisión\")\n",
    "ax.set_ylim(min(precision_ordenados) - 0.01, max(precision_ordenados) + 0.02)\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b1f55-2e28-4f23-8e1e-4a047ab3fe5f",
   "metadata": {},
   "source": [
    "## 4.2 Comparativa de Modelos Clasificación en función de métrica Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0e593-922e-4b49-a6cb-9ca5a4e07212",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    \"Árbol de Decisión\",\n",
    "    \"Random Forest\",\n",
    "    \"Regresión Logística\",\n",
    "    \"Red Neuronal\"\n",
    "]\n",
    "# Se añaden valores manualmente porque en cada ejecución cambian. Y estos gráficos se usaron para la explicación de la memoría.\n",
    "# es por ello, que a pesar de que pueden tomar lo valores de forma automatica, se ha decidido ponerlos manual.\n",
    "recall_scores = [0.125, 0.125, 0.500, 0.125]  # Valores manuales\n",
    "\n",
    "# Ordenación de de mayor a menor\n",
    "orden = sorted(zip(recall_scores, modelos), reverse=True)\n",
    "recall_ordenados, modelos_ordenados = zip(*orden)\n",
    "\n",
    "# Generación del gráfico\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(modelos_ordenados, recall_ordenados, color='skyblue')\n",
    "\n",
    "# Resaltado del mejor de los 4 modelos\n",
    "bars[0].set_color('mediumseagreen')\n",
    "\n",
    "# Etiquetado de valores\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval + 0.001, f\"{yval:.3f}\",\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Mejora de la gráfica\n",
    "ax.set_title(\"Comparativa de Modelos de Clasificación (Recall)\", fontsize=14, weight='bold')\n",
    "ax.set_ylabel(\"Recall\")\n",
    "ax.set_ylim(min(recall_ordenados) - 0.005, max(recall_ordenados) + 0.01)\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35239928-6e84-4178-8e45-a38efb57c50d",
   "metadata": {},
   "source": [
    "## 4.2 Comparativa de Modelos Clasificación en función de métrica AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08a71a-0110-4bca-bba1-4d05d5d95a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    \"Árbol de Decisión\",\n",
    "    \"Random Forest\",\n",
    "    \"Regresión Logística\",\n",
    "    \"Red Neuronal\"\n",
    "]\n",
    "# Se añaden valores manualmente porque en cada ejecución cambian. Y estos gráficos se usaron para la explicación de la memoría.\n",
    "# es por ello, que a pesar de que pueden tomar lo valores de forma automatica, se ha decidido ponerlos manual.\n",
    "auc_scores = [0.426, 0.353, 0.330, 0.556]  # valores manuales\n",
    "\n",
    "# Ordenación de modelos de mayor a menor AUC\n",
    "orden = sorted(zip(auc_scores, modelos), reverse=True)\n",
    "auc_ordenados, modelos_ordenados = zip(*orden)\n",
    "\n",
    "# Generación del gráfico\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(modelos_ordenados, auc_ordenados, color='skyblue')\n",
    "\n",
    "# Resaltado del mejor de los 4 modelos\n",
    "bars[0].set_color('mediumseagreen')\n",
    "\n",
    "# Etiquetado de valores\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f\"{yval:.3f}\",\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Mejora de la gráfica\n",
    "ax.set_title(\"Comparativa de Modelos de Clasificación (AUC-ROC)\", fontsize=14, weight='bold')\n",
    "ax.set_ylabel(\"AUC\")\n",
    "ax.set_ylim(min(auc_ordenados) - 0.01, max(auc_ordenados) + 0.02)\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c907ea04-fd19-4c65-869c-64235ca62d46",
   "metadata": {},
   "source": [
    "# 5 Ejemplo de Predicción con el Mejor Modelo\n",
    "Ejemplo de demostracion de como el mejor de los modelos, en este caso: Red Neuronal, predice un caso hipotético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a703a8-3301-4149-b43e-66864e3dba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Estandarizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n",
    "\n",
    "# Predicción para un caso hipotético\n",
    "nuevo_paciente = pd.DataFrame({\n",
    "    \"Carbohidratos\": [200],\n",
    "    \"Azucares\": [90],\n",
    "    \"Alcohol\": [10]\n",
    "})\n",
    "\n",
    "# Escalar si el modelo lo necesita (Solo si es regresión Logística o Red Neuronal). \n",
    "# Transformar los datos del nuevo paciente a la misma escala que los datos usados para entrenar el modelo (media = 0  y desviación estandar = 1).\n",
    "nuevo_paciente_scaled = scaler.transform(nuevo_paciente)\n",
    "\n",
    "# Crear y entrenar nuevamente el modelo final\n",
    "modelo_final = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "modelo_final.fit(X_train_resampled_scaled, y_train_resampled)\n",
    "\n",
    "# Predicción\n",
    "prediccion = modelo_final.predict(nuevo_paciente_scaled)\n",
    "probabilidad = modelo_final.predict_proba(nuevo_paciente_scaled)[0][1]\n",
    "\n",
    "print(f\"¿Existe la posibilidad de que usted padezca o desarrollo cáncer de colon en el futuro?: {'Sí' if prediccion[0] == 2 else 'No'} (Probabilidad: {probabilidad:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
